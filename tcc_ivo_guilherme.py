# -*- coding: utf-8 -*-
"""TCC_Ivo Guilherme.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uSDMyVHDthtgaEakisKsFp6EKIaYGVy1
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
import seaborn as sns; sns.set()
import csv

 
from google.colab import drive 
drive.mount('/content/gdrive')

 
df = pd.read_csv("gdrive/MyDrive/dataset_ocorrencias.csv",sep=';')
df

print('NaN occurrences in Columns:')
print(df.isnull().sum(axis = 0))
print('NaN occurrences in Rows:')
print(df.isnull().sum(axis = 1))

import datetime
df.dropna(axis=0,how='any',subset=['lat_ocorrencia','lon_ocorrencia'],inplace=True)


X=df.loc[:,['id_ocorrencia','cidade','horario','lat_ocorrencia','lon_ocorrencia','tipo']]
X =  X.loc[X['cidade'] == 'Florianópolis']
X =  X.loc[X['tipo'] == 'ATENDIMENTO PRÉ-HOSPITALAR']
X = X.loc[X["lon_ocorrencia"] >= -48.6,:]

X = X.drop_duplicates(subset ="id_ocorrencia",keep='first')
kmeans = KMeans(n_clusters = 4, init ='k-means++')
kmeans.fit(X[X.columns[3:5]]) 
X['cluster_label'] = kmeans.fit_predict(X[X.columns[3:5]])
centers = kmeans.cluster_centers_ 
labels = kmeans.predict(X[X.columns[3:5]]) 


Data = pd.DataFrame()

X["data_dia"] = pd.to_datetime(X["horario"],infer_datetime_format = True).dt.floor('1D')
X['cluster_label'] = X['cluster_label'].astype('category')
v = X.groupby(['data_dia', 'cluster_label']).size().unstack(fill_value=0)

#v.to_csv('gdrive/MyDrive/dataset_ocorrencias_clusters.csv', sep = ';', float_format = '%g')
v

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

fig = plt.figure(figsize = (6,6))
df_mapa = X
sns.scatterplot(x= "lon_ocorrencia", y="lat_ocorrencia", hue= "cluster_label",   data= df_mapa)
plt.xlim(-48.8, -48.2)
#plt.show()

df_cluster = pd.read_csv('gdrive/MyDrive/dataset_ocorrencias_clusters.csv', sep = ';')
df_cluster = df_cluster.set_index('data_dia')
df_cluster

from pandas import DataFrame
from pandas import concat
 
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
	n_vars = 1 if type(data) is list else data.shape[1]
	df = DataFrame(data)
	cols, names = list(), list()
	for i in range(n_in, 0, -1):
		cols.append(df.shift(i))
		names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
	for i in range(0, n_out):
		cols.append(df.shift(-i))
		if i == 0:
			names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
		else:
			names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
	agg = concat(cols, axis=1)
	agg.columns = names

	if dropnan:
		agg.dropna(inplace=True)
	return agg
 
values = list(range(10) )
data = series_to_supervised(values, 3, 1)

"""# Cluster 0 - 3 dias

"""

def0= pd.DataFrame(df_cluster['0'])
def0_3 = series_to_supervised(def0, n_in=3, n_out=1)
def0_3

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data0_3 = def0_3

# Separação em conjuntos de treino e teste
array = data0_3.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
Xc0 = X.copy()
yc0 =Y.copy()

test_size = 0.20
seed = 7
X_train_c0_3, X_test_c0_3, Y_train_c0_3, Y_test_c0_3 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
#scoring = 'r2'

scoring = ["r2", "neg_mean_squared_error"]
results_todos_c0 = []

models = []
models.append(('LR_0_3',(LinearRegression())))
models.append(('KNN_0_3',(KNeighborsRegressor())))
models.append(('RDF_0_3',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c0_3, Y_train_c0_3)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c0.append([name, msetr, mseval, r2tr, r2val, 3])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

results_testes_cAll = []
model = LinearRegression().fit(X_train_c0_3, Y_train_c0_3)
name = "LinearRegression:"

y_pred = model.predict(X_test_c0_3)
teste_R2 = r2_score(Y_test_c0_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c0_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 0])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c0_3, Y_train_c0_3)
name = "RandomForests:"

y_pred = model.predict(X_test_c0_3)
teste_R2 = r2_score(Y_test_c0_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c0_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 0])
results_testes_cAll

"""# Cluster 1 - 3 dias"""

def1= pd.DataFrame(df_cluster['1'])
def1_3 = series_to_supervised(def1, n_in=3, n_out=1)
def1_3

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data1_3 = def1_3

# Separação em conjuntos de treino e teste
array = data1_3.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
Xc1 = X.copy()
yc1 = Y.copy()

test_size = 0.20
seed = 7
X_train_c1_3, X_test_c1_3, Y_train_c1_3, Y_test_c1_3 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

results_todos_c1 = []


models = []
models.append(('LR_1_3',(LinearRegression())))
models.append(('KNN_1_3',(KNeighborsRegressor())))
models.append(('RDF_1_3',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c1_3, Y_train_c1_3)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c1.append([name, msetr, mseval, r2tr, r2val, 3])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c1_3, Y_train_c1_3)
name = "LinearRegression:"

y_pred = model.predict(X_test_c1_3)
teste_R2 = r2_score(Y_test_c1_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c1_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 1])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c1_3, Y_train_c1_3)
name = "RandomForests:"

y_pred = model.predict(X_test_c1_3)
teste_R2 = r2_score(Y_test_c1_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c1_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 1])
results_testes_cAll

"""# Cluster 2 - 3 dias"""

def2= pd.DataFrame(df_cluster['2'])
def2_3 = series_to_supervised(def2, n_in=3, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data2_3 = def2_3

# Separação em conjuntos de treino e teste
array = data2_3.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
Xc2 = X.copy()
yc2 = Y.copy()

test_size = 0.20
seed = 7
X_train_c2_3, X_test_c2_3, Y_train_c2_3, Y_test_c2_3 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

results_todos_c2 = []

models = []
models.append(('LR_2_3',(LinearRegression())))
models.append(('KNN_2_3',(KNeighborsRegressor())))
models.append(('RDF_2_3',(RandomForestRegressor())))
np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c2_3, Y_train_c2_3)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c2.append([name, msetr, mseval, r2tr, r2val, 3])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c2_3, Y_train_c2_3)
name = "LinearRegression:"

y_pred = model.predict(X_test_c2_3)
teste_R2 = r2_score(Y_test_c2_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c2_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 2])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c2_3, Y_train_c2_3)
name = "RandomForests:"

y_pred = model.predict(X_test_c2_3)
teste_R2 = r2_score(Y_test_c2_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c2_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 2])
results_testes_cAll

"""# Cluster 3 - 3 dias"""

def3= pd.DataFrame(df_cluster['3'])
def3_3 = series_to_supervised(def3, n_in=3, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data3_3 = def3_3

# Separação em conjuntos de treino e teste
array = data3_3.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
Xc3 = X.copy()
yc3 = Y.copy()

test_size = 0.20
seed = 7
X_train_c3_3, X_test_c3_3, Y_train_c3_3, Y_test_c3_3 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

results_todos_c3 = []

models = []
models.append(('LR_3_3',(LinearRegression())))
models.append(('KNN_3_3',(KNeighborsRegressor())))
models.append(('RDF_3_3',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c3_3, Y_train_c3_3)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c3.append([name, msetr, mseval, r2tr, r2val, 3])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c3_3, Y_train_c3_3)
name = "LinearRegression:"

y_pred = model.predict(X_test_c3_3)
teste_R2 = r2_score(Y_test_c3_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c3_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 3])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c3_3, Y_train_c3_3)
name = "RandomForests:"

y_pred = model.predict(X_test_c3_3)
teste_R2 = r2_score(Y_test_c3_3, y_pred)
teste_MSE = mean_squared_error(Y_test_c3_3, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 3])
results_testes_cAll

X_c0_c3= np.hstack((Xc0, Xc1, Xc2, Xc3))
Xc0_c3_tr, Xc0_c3_te, ytr, yte = train_test_split(X_c0_c3, yc0, random_state = seed)
lr = LinearRegression().fit(Xc0_c3_tr, ytr)
ypred = lr.predict(Xc0_c3_te)
teste_R2 = r2_score(yte, ypred)
teste_MSE = mean_squared_error(yte, ypred)
resultado_3_3=(teste_R2, teste_MSE)
resultado_3_3

X_c1_c3= np.hstack((Xc0, Xc1, Xc2, Xc3))
Xc1_c3_tr, Xc1_c3_te, ytr, yte = train_test_split(X_c1_c3, yc1, random_state = seed)
lr = LinearRegression().fit(Xc1_c3_tr, ytr)
ypred = lr.predict(Xc1_c3_te)
teste_R2 = r2_score(yte, ypred)
teste_MSE = mean_squared_error(yte, ypred)
resultado_3_3=(teste_R2, teste_MSE)
resultado_3_3

X_c1_c3= np.hstack((Xc0, Xc1, Xc2, Xc3))
Xc1_c3_tr, Xc1_c3_te, ytr, yte = train_test_split(X_c1_c3, yc2, random_state = seed)
lr = LinearRegression().fit(Xc1_c3_tr, ytr)
ypred = lr.predict(Xc1_c3_te)
teste_R2 = r2_score(yte, ypred)
teste_MSE = mean_squared_error(yte, ypred)
resultado_3_3=(teste_R2, teste_MSE)
resultado_3_3

X_c1_c3= np.hstack((Xc0, Xc1, Xc2, Xc3))
Xc1_c3_tr, Xc1_c3_te, ytr, yte = train_test_split(X_c1_c3, yc3, random_state = seed)
lr = LinearRegression().fit(Xc1_c3_tr, ytr)
ypred = lr.predict(Xc1_c3_te)
teste_R2 = r2_score(yte, ypred)
teste_MSE = mean_squared_error(yte, ypred)
resultado_3_3=(teste_R2, teste_MSE)
resultado_3_3

from pandas import DataFrame
from pandas import concat
 
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
	n_vars = 1 if type(data) is list else data.shape[1]
	df = DataFrame(data)
	cols, names = list(), list()
	for i in range(n_in, 0, -1):
		cols.append(df.shift(i))
		names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
	for i in range(0, n_out):
		cols.append(df.shift(-i))
		if i == 0:
			names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
		else:
			names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
	agg = concat(cols, axis=1)
	agg.columns = names

	if dropnan:
		agg.dropna(inplace=True)
	return agg
 
values = list(range(10) )
data = series_to_supervised(values, 7, 1)
print(data)

"""# Cluster 0 - 7 dias"""

def0= pd.DataFrame(df_cluster['0'])
def0_7 = series_to_supervised(def0, n_in=7, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data0_7 = def0_7

# Separação em conjuntos de treino e teste
array = data0_7.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train_c0_7, X_test_c0_7, Y_train_c0_7, Y_test_c0_7 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]



models = []
models.append(('LR_0_7',(LinearRegression())))
models.append(('KNN_0_7',(KNeighborsRegressor())))
models.append(('RDF_0_7',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c0_7, Y_train_c0_7)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c0.append([name, msetr, mseval, r2tr, r2val, 7])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c0_7, Y_train_c0_7)
name = "LinearRegression:"

y_pred = model.predict(X_test_c0_7)
teste_R2 = r2_score(Y_test_c0_7, y_pred)
teste_MSE = mean_squared_error(Y_test_c0_7, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 0])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c0_7, Y_train_c0_7)
name = "RandomForests:"

y_pred = model.predict(X_test_c0_7)
teste_R2 = r2_score(Y_test_c0_7, y_pred)
teste_MSE = mean_squared_error(Y_test_c0_7, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 0])
results_testes_cAll

"""# Cluster 1 - 7 dias"""

def1= pd.DataFrame(df_cluster['1'])
def1_7 = series_to_supervised(def1, n_in=7, n_out=1)
def1_7

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data1_7 = def1_7

# Separação em conjuntos de treino e teste
array = data1_7.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

models = []
models.append(('LR_1_7',(LinearRegression())))
models.append(('KNN_1_7',(KNeighborsRegressor())))
models.append(('RDF_1_7',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train, Y_train)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c1.append([name, msetr, mseval, r2tr, r2val, 7])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train, Y_train)
name = "LinearRegression:"

y_pred = model.predict(X_test)
teste_R2 = r2_score(Y_test, y_pred)
teste_MSE = mean_squared_error(Y_test+1, y_pred+1)
results_testes_cAll.append([name, teste_R2, teste_MSE, 1])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train, Y_train)
name = "RandomForests:"

y_pred = model.predict(X_test)
teste_R2 = r2_score(Y_test, y_pred)
teste_MSE = mean_squared_error(Y_test+1, y_pred+1)
results_testes_cAll.append([name, teste_R2, teste_MSE, 1])
results_testes_cAll

"""# Cluster 2 - 7 dias"""

def2= pd.DataFrame(df_cluster['2'])
def2_7 = series_to_supervised(def2, n_in=7, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data2_7 = def2_7

# Separação em conjuntos de treino e teste
array = data2_7.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train_c2_7, X_test_c2_7, Y_train_c2_7, Y_test_c2_7 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

models = []
models.append(('LR_2_7',(LinearRegression())))
models.append(('KNN_2_7',(KNeighborsRegressor())))
models.append(('RDF_2_7',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c2_7, Y_train_c2_7)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c2.append([name, msetr, mseval, r2tr, r2val, 7])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c2_7, Y_train_c2_7)
name = "LinearRegression:"

y_pred = model.predict(X_test_c2_7)
teste_R2 = r2_score(Y_test_c2_7, y_pred)
teste_MSE = mean_squared_error(Y_test_c2_7, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 2])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c2_7, Y_train_c2_7)
name = "RandomForests:"

y_pred = model.predict(X_test_c2_7)
teste_R2 = r2_score(Y_test_c2_7, y_pred)
teste_MSE = mean_squared_error(Y_test_c2_7, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 2])
results_testes_cAll

"""# Cluster 3 - 7 dias"""

def3= pd.DataFrame(df_cluster['3'])
def3_7 = series_to_supervised(def3, n_in=7, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor


data3_7 = def3_7

# Separação em conjuntos de treino e teste
array = data3_7.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train_c3_7, X_test_c3_7, Y_train_c3_7, Y_test_c3_7 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

models = []
models.append(('LR_3_7',(LinearRegression())))
models.append(('KNN_3_7',(KNeighborsRegressor())))
models.append(('RDF_3_7',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c3_7, Y_train_c3_7)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c3.append([name, msetr, mseval, r2tr, r2val, 7])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c3_7, Y_train_c3_7)
name = "LinearRegression:"

y_pred = model.predict(X_test_c3_7)
teste_R2 = r2_score(Y_test_c3_7, y_pred)
teste_MSE = mean_squared_error(Y_test_c3_7, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 3])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c3_7, Y_train_c3_7)
name = "RandomForests:"

y_pred = model.predict(X_test_c3_7)
teste_R2 = r2_score(Y_test_c3_7, y_pred)
teste_MSE = mean_squared_error(Y_test_c3_7, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 3])
results_testes_cAll

from pandas import DataFrame
from pandas import concat
 
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
	n_vars = 1 if type(data) is list else data.shape[1]
	df = DataFrame(data)
	cols, names = list(), list()
	for i in range(n_in, 0, -1):
		cols.append(df.shift(i))
		names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
	for i in range(0, n_out):
		cols.append(df.shift(-i))
		if i == 0:
			names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
		else:
			names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
	agg = concat(cols, axis=1)
	agg.columns = names

	if dropnan:
		agg.dropna(inplace=True)
	return agg
 
values = list(range(10) )
data = series_to_supervised(values, 28, 1)
print(data)

"""# Cluster 0 - 28 dias"""

def0= pd.DataFrame(df_cluster['0'])
def0_28 = series_to_supervised(def0, n_in=28, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data0_28 = def0_28

# Separação em conjuntos de treino e teste
array = data0_28.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train_c0_28, X_test_c0_28, Y_train_c0_28, Y_test_c0_28 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]


models = []
models.append(('LR_0_28',(LinearRegression())))
models.append(('KNN_0_28',(KNeighborsRegressor())))
models.append(('RND_0_28',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c0_28, Y_train_c0_28)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c0.append([name, msetr, mseval, r2tr, r2val, 28])
  results_todos_c0

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c0_28, Y_train_c0_28)
name = "LinearRegression:"

y_pred = model.predict(X_test_c0_28)
teste_R2 = r2_score(Y_test_c0_28, y_pred)
teste_MSE = mean_squared_error(Y_test_c0_28, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 0])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c0_28, Y_train_c0_28)
name = "RandomForests:"

y_pred = model.predict(X_test_c0_28)
teste_R2 = r2_score(Y_test_c0_28, y_pred)
teste_MSE = mean_squared_error(Y_test_c0_28, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 0])
results_testes_cAll

"""# Cluster 1 - 28 dias"""

def1= pd.DataFrame(df_cluster['1'])
def1_28 = series_to_supervised(def1, n_in=28, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data1_28 = def1_28

# Separação em conjuntos de treino e teste
array = data1_28.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

models = []
models.append(('LR_1_28',(LinearRegression())))
models.append(('KNN_1_28',(KNeighborsRegressor())))
models.append(('RND_1_28',(RandomForestRegressor())))
np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train, Y_train)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c1.append([name, msetr, mseval, r2tr, r2val, 28])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train, Y_train)
name = "LinearRegression:"

y_pred = model.predict(X_test)
teste_R2 = r2_score(Y_test, y_pred)
teste_MSE = mean_squared_error(Y_test, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 1])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train, Y_train)
name = "RandomForests:"

y_pred = model.predict(X_test)
teste_R2 = r2_score(Y_test, y_pred)
teste_MSE = mean_squared_error(Y_test, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 1])
results_testes_cAll

"""# Cluster 2 - 28 dias"""

def2= pd.DataFrame(df_cluster['2'])
def2_28 = series_to_supervised(def2, n_in=28, n_out=1)
def2_28

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor


data2_28 = def2_28

# Separação em conjuntos de treino e teste
array = data2_28.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train_c2_28, X_test_c2_28, Y_train_c2_28, Y_test_c2_28 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

models = []
models.append(('LR_2_28',(LinearRegression())))
models.append(('KNN_2_28',(KNeighborsRegressor())))
models.append(('RND_2_28',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c2_28, Y_train_c2_28)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c2.append([name, msetr, mseval, r2tr, r2val, 28])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c2_28, Y_train_c2_28)
name = "LinearRegression:"

y_pred = model.predict(X_test_c2_28)
teste_R2 = r2_score(Y_test_c2_28, y_pred)
teste_MSE = mean_squared_error(Y_test_c2_28, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 2])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c2_28, Y_train_c2_28)
name = "RandomForests:"

y_pred = model.predict(X_test_c2_28)
teste_R2 = r2_score(Y_test_c2_28, y_pred)
teste_MSE = mean_squared_error(Y_test_c2_28, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 2])
results_testes_cAll

"""# Cluster 3 - 28 dias"""

def3= pd.DataFrame(df_cluster['3'])
def3_28 = series_to_supervised(def3, n_in=28, n_out=1)

import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay

from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsRegressor

data3_28 = def3_28

# Separação em conjuntos de treino e teste
array = data3_28.values
X = array[:, 0:-1].astype(float)
Y = array[:,-1]
test_size = 0.20
seed = 7
X_train_c3_28, X_test_c3_28, Y_train_c3_28, Y_test_c3_28 = train_test_split(X, Y, test_size=test_size, random_state=seed)

num_folds = 5
scoring = ["r2", "neg_mean_squared_error"]

models = []
models.append(('LR_3_28',(LinearRegression())))
models.append(('KNN_3_28',(KNeighborsRegressor())))
models.append(('RND_3_28',(RandomForestRegressor())))

np.random.seed(7)
results = []
names = []
for name, model in models:
  gs = GridSearchCV(
    model,
    param_grid={},
    scoring=scoring,
    refit="r2",
    n_jobs=2,
    return_train_score=True,
    )
  gs.fit(X_train_c3_28, Y_train_c3_28)
  results = gs.cv_results_
  r2tr=results["mean_train_r2"][0]
  r2val=results["mean_test_r2"][0]
  msetr=results["mean_train_neg_mean_squared_error"][0]
  mseval=results["mean_test_neg_mean_squared_error"][0]
  msetr= -(msetr)
  mseval= -(mseval)
  print(name, msetr, mseval, r2tr, r2val)
  results_todos_c3.append([name, msetr, mseval, r2tr, r2val, 28])

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = LinearRegression().fit(X_train_c3_28, Y_train_c3_28)
name = "LinearRegression:"

y_pred = model.predict(X_test_c3_28)
teste_R2 = r2_score(Y_test_c3_28, y_pred)
teste_MSE = mean_squared_error(Y_test_c3_28, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 3])
results_testes_cAll

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

model = RandomForestRegressor().fit(X_train_c3_28, Y_train_c3_28)
name = "RandomForests:"

y_pred = model.predict(X_test_c3_28)
teste_R2 = r2_score(Y_test_c3_28, y_pred)
teste_MSE = mean_squared_error(Y_test_c3_28, y_pred)
results_testes_cAll.append([name, teste_R2, teste_MSE, 3])
results_testes_cAll

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
df_results_testes_cAll = pd.DataFrame(results_testes_cAll, columns = ["Algoritmo","teste_R2", "teste_MSE", "Cluster", "Janela Temporal"])
ax = sns.boxplot(x = "Cluster", y = "teste_R2", hue = "Algoritmo", data = df_results_testes_cAll, palette="Set3", linewidth=2.5)

import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt
df_results_testes_cAll = pd.DataFrame(results_testes_cAll, columns = ["Algoritmo","teste_R2", "teste_MSE", "Cluster"])
ax = sns.boxplot(x = "Cluster", y = "teste_R2", hue = "Algoritmo", data = df_results_testes_cAll, palette="Set3", linewidth=2.5)

"""# Dicionário
id_ocorrencia - identificação única da ocorrência

cidade - A cidade onde aconteceu a ocorrência

população - Pupulação da cidade

horario - horario da ocorrencia com data e hora

vtr - viatura empenhanha na ocorrencia

mtcl - matricula do militar ou cpf do Bombeiro comunitario

militar_bc - identificação se o individuo é Bombeiro Comunitário ou Bombeiro Militar

bc_indenizado - Identifica se o Bombeiro Comunitario estava no serviço sendo pago(indenizado) ou não

obm - Organização Bombeiro Militar que estava na ocorrência

coordenada_obm - Coordenada da organização Bombeiro Militar

coordenada_ocorrencia - Coordenada da Ocorrência

lat_ocorrencia - Latitude ocorrência

lon_ocorrencia - Longitude Ocorrência

tipo - Tipo da ocorrência, pode ser Atendimento pré-hospitalar - APH, incendio, acidente e outros.

subtipo - especifica o tipo, num APH, pode especificar desmaio, nem sempre é preenchido.

tempo_resposta - Tempo do acionamento até a chegada ao local da ocorrêcia, pode ser um dado que estaja bem falho, pois acontece do bombeiro esquecer de clicar no botão

tempo_total_empenho - tempo total da saída da obm até a chegada a obm novamente. firecast - indica se uma viatura utilizou o sistema "firecast" para dar J-9, J-10, J-11 e J-12 nos deslocamentos

origem_samu - Se foi um repasse da ocorrência que era do samu

vitima - geração no sistema, talvez de pra gerar o número de vítimas, nome, idade, alguns sinais vitais.
"""